import io
import re
from datetime import datetime, timedelta
from etl.import_harvest_csv import upsert_raw_to_harvest_fact

import pandas as pd
import streamlit as st
from sqlalchemy.exc import SQLAlchemyError

from app.core.db import get_engine, DB_PATH
from app.core.auth import require_login

require_login()

st.markdown("### CSV ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
st.caption("åé‡ãƒ‡ãƒ¼ã‚¿CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€harvest_fact ã«åæ˜ ã—ã¾ã™ã€‚")
st.write(f"ç¾åœ¨ã®DBãƒ‘ã‚¹: `{DB_PATH}`")

# ---------- helpers ----------
ZEN_NUM = str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼ï¼Œ", "0123456789.,")
EXCEL_EPOCH = datetime(1899, 12, 30)

def parse_amount_to_kg(val) -> float | None:
    """'1234', '1,234', '12.3kg', '123g' ç­‰ã‚’ kg(float) ã«ã™ã‚‹"""
    if val is None:
        return None
    s = str(val).strip()
    if not s:
        return None

    s = s.translate(ZEN_NUM).replace(",", "")
    s_low = s.lower()

    m = re.search(r"[-+]?\d*\.?\d+", s_low)
    if not m:
        return None
    x = float(m.group())

    if "kg" in s_low:
        return x
    return x / 1000.0

def parse_harvest_date(val) -> str | None:
    """
    å—ã‘ã‚‹ä¾‹:
    - 2025/8/18, 2025/08/18, 2025-08-18
    - Excelã‚·ãƒªã‚¢ãƒ« (30000~60000ç¨‹åº¦)
    """
    if val is None:
        return None
    s = str(val).strip()
    if not s:
        return None

    # Excelã‚·ãƒªã‚¢ãƒ«
    if s.isdigit():
        n = int(s)
        if 30000 <= n <= 60000:
            return (EXCEL_EPOCH + timedelta(days=n)).date().isoformat()

    for fmt in ("%Y/%m/%d", "%Y-%m-%d", "%Y/%m/%d %H:%M:%S", "%Y-%m-%d %H:%M:%S"):
        try:
            return datetime.strptime(s, fmt).date().isoformat()
        except ValueError:
            pass

    dt = pd.to_datetime(s, errors="coerce")
    if pd.isna(dt):
        return None
    return dt.date().isoformat()

def read_csv_bytes(bytes_data: bytes) -> tuple[pd.DataFrame, str]:
    candidates = [
        ("utf-8-sig", dict(encoding="utf-8-sig", sep=",")),
        ("cp932",     dict(encoding="cp932", sep=",")),
        ("cp932_auto", dict(encoding="cp932", sep=None, engine="python")),
    ]
    last_errs = []
    for label, params in candidates:
        try:
            buf = io.BytesIO(bytes_data)
            df = pd.read_csv(buf, **params)
            return df, label
        except Exception as e:
            last_errs.append(f"{label}: {e}")
    raise RuntimeError("CSV decode failed:\n" + "\n".join(last_errs))

def ensure_harvest_fact_table():
    ddl = """
    CREATE TABLE IF NOT EXISTS harvest_fact (
        id           INTEGER PRIMARY KEY AUTOINCREMENT,
        harvest_date TEXT NOT NULL,
        company      TEXT NOT NULL,
        crop         TEXT NOT NULL,
        amount_kg    REAL NOT NULL
    );
    """
    engine = get_engine()
    with engine.begin() as conn:
        conn.exec_driver_sql(ddl)

def normalize_amount_for_compare(x):
    """
    é‡è¤‡åˆ¤å®šç”¨: amount_kg ã‚’å°‘æ•°3æ¡ã«ä¸¸ã‚ã¦æ¯”è¼ƒã™ã‚‹
    - DBã‹ã‚‰æ–‡å­—åˆ—ã§æ¥ã¦ã‚‚OK
    â€ None/Nanã¯ None ã‚’è¿”ã™
    """
    if x is None:
        return None
    try:
        # æ–‡å­—åˆ—â†’æ•°å€¤ã¸("1.23"ã€€ç­‰ã‚‚OK)
        v = float(x)
    except (TypeError, ValueError):
        return None
    return round(v, 3)



# ---------- upload ----------
uploaded = st.file_uploader("åé‡CSVã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", type=["csv"])
if uploaded is None:
    st.stop()

bytes_data = uploaded.getvalue()

try:
    raw_df, used_label = read_csv_bytes(bytes_data)
except Exception as e:
    st.error("CSVã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    st.exception(e)
    st.stop()

st.success(f"CSVã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ (mode={used_label})")

# ---------- normalize columns ----------
col_map = {
    "åç©«æ—¥": "harvest_date",
    "æ—¥ä»˜": "harvest_date",
    "ä¼æ¥­å": "company",
    "ä¼šç¤¾å": "company",
    "ä½œç‰©å": "crop",
    "åç©«é‡èœå": "crop",
    "å“ç›®": "crop",
    "åç©«é‡ï¼ˆï½‡ï¼‰": "amount_g",
    "åç©«é‡(ï½‡)": "amount_g",
    "åç©«é‡": "amount_g",
    "é‡": "amount_g",
    "åé‡(ã)": "amount_kg",
    "åé‡(kg)": "amount_kg",
}

df = raw_df.rename(columns={c: col_map.get(str(c).strip(), str(c).strip()) for c in raw_df.columns})

required_any = {"harvest_date", "company", "crop"}
if not required_any.issubset(df.columns):
    st.error(f"å¿…é ˆåˆ—ãŒè¶³ã‚Šã¾ã›ã‚“ã€‚å¿…è¦: {sorted(required_any)} / ç¾åœ¨: {list(df.columns)}")
    st.stop()

# amount_kg ã‚’ä½œã‚‹
if "amount_kg" in df.columns:
    df["amount_kg"] = df["amount_kg"].apply(normalize_amount_for_compare)
elif "amount_g" in df.columns:
    df["amount_kg"] = df["amount_g"].apply(normalize_amount_for_compare)
else:
    st.error("åé‡åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆamount_g / amount_kg ç›¸å½“ãŒå¿…è¦ï¼‰ã€‚")
    st.stop()

# æ—¥ä»˜/æ–‡å­—åˆ—ã‚’æ­£è¦åŒ–
df["harvest_date"] = df["harvest_date"].apply(parse_harvest_date)
df["company"] = df["company"].astype(str).str.strip()
df["crop"] = df["crop"].astype(str).str.strip()

# ---------- cleansing ----------
before = len(df)

df = df.dropna(subset=["harvest_date", "company", "crop", "amount_kg"])
df = df[(df["company"] != "") & (df["crop"] != "")]

# æœªæ¥æ—¥é™¤å¤–
today = pd.Timestamp.today().date()
future_mask = pd.to_datetime(df["harvest_date"], errors="coerce").dt.date > today
future_rows = df[future_mask].copy()
df = df[~future_mask]

# ãƒã‚¤ãƒŠã‚¹é™¤å¤–
neg_mask = df["amount_kg"] < 0
neg_rows = df[neg_mask].copy()
df = df[~neg_mask]

# é‡è¤‡åˆ¤å®šç”¨ã« amount_kg ã‚’ä¸¸ã‚ã‚‹ï¼ˆâ€»DBä¿å­˜å€¤ã‚‚åŒã˜ä¸¸ã‚ã§æƒãˆã‚‹ã¨æœ€å¼·ï¼‰
df["amount_kg"] = df["amount_kg"].apply(lambda x: None if x is None else normalize_amount_for_compare(x))

after = len(df)
dropped = before - after

st.info(
    f"""**ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°çµæœ**
- å…ƒãƒ‡ãƒ¼ã‚¿: {before} è¡Œ
- æœ‰åŠ¹: {after} è¡Œ
- æ¬ æ/ä¸æ­£é™¤å¤–: {dropped} è¡Œ
- æœªæ¥æ—¥é™¤å¤–: {len(future_rows)} è¡Œ
- ãƒã‚¤ãƒŠã‚¹é™¤å¤–: {len(neg_rows)} è¡Œ
"""
)

if not future_rows.empty:
    with st.expander("é™¤å¤–ã•ã‚ŒãŸæœªæ¥æ—¥ã®è¡Œï¼ˆå…ˆé ­10ä»¶ï¼‰"):
        st.dataframe(future_rows.head(10), width="stretch")

if not neg_rows.empty:
    with st.expander("é™¤å¤–ã•ã‚ŒãŸãƒã‚¤ãƒŠã‚¹åé‡ã®è¡Œï¼ˆå…ˆé ­10ä»¶ï¼‰"):
        st.dataframe(neg_rows.head(10), width="stretch")

if df.empty:
    st.error("æœ‰åŠ¹ãªãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚CSVã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

st.markdown("### ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°å¾Œï¼‰")
st.dataframe(df.head(20), width="stretch")

# ---------- duplicate check ----------
ensure_harvest_fact_table()

merge_cols = ["harvest_date", "company", "crop", "amount_kg"]
df = df[merge_cols].copy()

engine = get_engine()
with st.spinner("DB æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨ã®é‡è¤‡ã‚’ãƒã‚§ãƒƒã‚¯ä¸­..."):
    try:
        with engine.connect() as conn:
            existing = pd.read_sql_query(
                "SELECT harvest_date, company, crop, amount_kg FROM harvest_fact",
                conn,
            )
            # æ—¢å­˜å´ã‚‚ä¸¸ã‚ã¦æ¯”è¼ƒã®è»¸ã‚’æƒãˆã‚‹ï¼ˆæµ®å‹•å°æ•°èª¤å·®å¯¾ç­–ï¼‰
            existing["amount_kg"] = existing["amount_kg"].apply(normalize_amount_for_compare)
            existing = existing.dropna(subset=["amount_kg"])
    except SQLAlchemyError:
        existing = pd.DataFrame(columns=merge_cols)

if existing.empty:
    df_new = df.copy()
    df_dup = pd.DataFrame(columns=merge_cols)
else:
    merged = df.merge(existing[merge_cols], how="left", on=merge_cols, indicator=True)
    df_new = merged[merged["_merge"] == "left_only"][merge_cols].copy()
    df_dup = merged[merged["_merge"] == "both"][merge_cols].copy()

st.subheader("é‡è¤‡ãƒã‚§ãƒƒã‚¯çµæœ")
st.write(f"æ–°è¦ãƒ‡ãƒ¼ã‚¿: **{len(df_new)} ä»¶**")
st.write(f"æ—¢å­˜ã¨é‡è¤‡: **{len(df_dup)} ä»¶**")

if len(df_dup) > 0:
    st.warning("ä»¥ä¸‹ã¯ DB ã«æ—¢ã«å­˜åœ¨ã—ã€ä»Šå›ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ã¯è¿½åŠ ã•ã‚Œã¾ã›ã‚“ï¼ˆå…ˆé ­10ä»¶ï¼‰ã€‚")
    st.dataframe(df_dup.head(10), width="stretch")

if len(df_new) == 0:
    st.info("è¿½åŠ ã§ãã‚‹æ–°è¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

st.markdown("### ğŸ”µ æ–°è¦ãƒ‡ãƒ¼ã‚¿ï¼ˆç™»éŒ²äºˆå®šï¼‰")
st.dataframe(df_new.head(20), width="stretch")

# ---------- insert ----------
if st.button("ã“ã®å†…å®¹ã§ harvest_fact ã«ç™»éŒ²ã™ã‚‹", type="primary"):
    with st.spinner("DBã«ç™»éŒ²ä¸­â€¦"):
        try:
            df_raw = df_new.rename(columns={
                "harvest_date": "c1",
                "company": "c2",
                "crop": "c3",
                "amount_kg": "c4",
            }).copy()

            df_raw["source_file"] = "csv_upload"

            with engine.begin() as conn:
                df_raw.to_sql(
                    "raw_csv",
                    conn,
                    if_exists="append",
                    index=False
                )

                inserted = upsert_raw_to_harvest_fact()

                st.success(
                    f"harvest_factã¸åæ˜ ã•ã‚Œã¾ã—ãŸã€‚"
                    f"ï¼ˆæ–°è¦å€™è£œ={len(df_new)}è¡Œ / å®Ÿéš›ã«åæ˜ ={inserted}è¡Œ)"
                )
        except SQLAlchemyError as e:
            st.error("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®ç™»éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.code(str(DB_PATH), language="bash")
            st.exception(e)
            st.stop()

    st.info("SearchList / Compass ã‚’å†èª­ã¿è¾¼ã¿ã™ã‚‹ã¨åæ˜ ã•ã‚Œã¾ã™ã€‚")
