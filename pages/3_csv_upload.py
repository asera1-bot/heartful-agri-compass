from __future__ import annotations

import io
import os
import re
from datetime import datetime, timedelta

import pandas as pd
import streamlit as st
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy import text

from app.core.auth import require_login
from app.core.db import get_engine, init_db
from app.common.constants import DB_PATH

st.set_page_config(page_title="CSV Upload", layout="wide")
require_login()
init_db()

if st.session_state.get("after_insert_message"):
    st.info(
        "CSVã®ç™»éŒ²ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n\n"
        "ğŸ”„ï¸ç™»éŒ²å†…å®¹ã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€å·¦ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰"
        "Compass ã¾ãŸã¯ Search List ãƒšãƒ¼ã‚¸ã‚’é–‹ããªãŠã—ã¦ãã ã•ã„ã€‚ \n"
        "(Streamlitã®ä»•æ§˜ä¸Šã€ä»–ãƒšãƒ¼ã‚¸ã¯è‡ªå‹•æ›´æ–°ã•ã‚Œã¾ã›ã‚“ã€‚ )"
    )
    del st.session_state["after_insert_message"]

st.title("CSV Upload")
st.caption("åé‡ãƒ‡ãƒ¼ã‚¿CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ harvest_fact ã«ç™»éŒ²ã—ã¾ã™ã€‚")
st.caption(f"DB_PATH={DB_PATH} exists={os.path.exists(DB_PATH)}")

# ---------- helpers ----------
ZEN_NUM = str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼ï¼Œ", "0123456789.,")
EXCEL_EPOCH = datetime(1899, 12, 30)

def parse_amount_to_kg(val) -> float | None:
    if val is None:
        return None
    s = str(val).strip()
    if not s:
        return None
    s = s.translate(ZEN_NUM).replace(",", "")
    s_low = s.lower()
    m = re.search(r"[-+]?\d*\.?\d+", s_low)
    if not m:
        return None
    x = float(m.group())
    if "kg" in s_low:
        return x
    # gæƒ³å®š
    return x / 1000.0

def parse_harvest_date(val) -> str | None:
    if val is None:
        return None
    s = str(val).strip()
    if not s:
        return None

    # Excelã‚·ãƒªã‚¢ãƒ«
    if s.isdigit():
        n = int(s)
        if 30000 <= n <= 60000:
            return (EXCEL_EPOCH + timedelta(days=n)).date().isoformat()

    for fmt in ("%Y/%m/%d", "%Y-%m-%d", "%Y/%m/%d %H:%M:%S", "%Y-%m-%d %H:%M:%S"):
        try:
            return datetime.strptime(s, fmt).date().isoformat()
        except ValueError:
            pass

    dt = pd.to_datetime(s, errors="coerce")
    if pd.isna(dt):
        return None
    return dt.date().isoformat()

def read_csv_bytes(b: bytes) -> tuple[pd.DataFrame, str]:
    candidates = [
        ("utf-8-sig", dict(encoding="utf-8-sig", sep=",")),
        ("cp932", dict(encoding="cp932", sep=",")),
        ("cp932_auto", dict(encoding="cp932", sep=None, engine="python")),
    ]
    last = []
    for label, params in candidates:
        try:
            buf = io.BytesIO(b)
            return pd.read_csv(buf, **params), label
        except Exception as e:
            last.append(f"{label}: {e}")
    raise RuntimeError("CSV decode failed:\n" + "\n".join(last))

def ensure_table():
    ddl = """
    CREATE TABLE IF NOT EXISTS harvest_fact (
        id           INTEGER PRIMARY KEY AUTOINCREMENT,
        harvest_date TEXT NOT NULL,
        company      TEXT NOT NULL,
        crop         TEXT NOT NULL,
        amount_kg    REAL NOT NULL
    );
    """
    eng = get_engine()
    with eng.begin() as conn:
        conn.exec_driver_sql(ddl)

def norm_col(x: str) -> str:
    return str(x).replace("\ufeff", "").replace("ã€€", " ").strip().lower()

COL_MAP = {
    "åç©«æ—¥": "harvest_date",
    "æ—¥ä»˜": "harvest_date",
    "harvest_date": "harvest_date",
    "date": "harvest_date",

    "ä¼æ¥­å": "company",
    "ä¼šç¤¾å": "company",
    "ä¼æ¥­": "company",
    "ä¼šç¤¾": "company",
    "company": "company",

    "ä½œç‰©å": "crop",
    "åç©«é‡èœå": "crop",
    "å“ç›®": "crop",
    "crop": "crop",

    "åç©«é‡ï¼ˆï½‡ï¼‰": "amount_g",
    "åç©«é‡(ï½‡)": "amount_g",
    "åç©«é‡": "amount_g",
    "é‡": "amount_g",
    "åé‡(ã)": "amount_kg",
    "åé‡(kg)": "amount_kg",
    "amount_g": "amount_g",
    "amount_kg": "amount_kg",
}

# ---------- UI ----------
uploaded = st.file_uploader("åé‡CSVã‚’é¸æŠ", type=["csv"])
if uploaded is None:
    st.info("CSVã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    st.stop()

raw_df, mode = read_csv_bytes(uploaded.getvalue())
st.success(f"CSVèª­ã¿è¾¼ã¿æˆåŠŸ (mode={mode})")
st.write("æ¤œå‡ºåˆ—:", list(raw_df.columns))

# ---------- normalize columns ----------
rename = {}
for c in raw_df.columns:
    key = norm_col(c)
    mapped = COL_MAP.get(key) or COL_MAP.get(str(c).replace("\ufeff", "").replace("ã€€", " ").strip())
    if mapped:
        rename[c] = mapped

df = raw_df.rename(columns=rename)

required = {"harvest_date", "company", "crop"}
if not required.issubset(df.columns):
    st.error(f"å¿…é ˆåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {required - set(df.columns)}")
    st.write("æ­£è¦åŒ–å¾Œã®åˆ—:", [norm_col(x) for x in raw_df.columns])
    st.stop()

# amount_kg ä½œæˆ
if "amount_kg" in df.columns:
    df["amount_kg"] = df["amount_kg"].apply(parse_amount_to_kg)
elif "amount_g" in df.columns:
    df["amount_kg"] = df["amount_g"].apply(parse_amount_to_kg)
else:
    st.error("åé‡åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆamount_g/amount_kg ãŒå¿…è¦ï¼‰")
    st.stop()

df["harvest_date"] = df["harvest_date"].apply(parse_harvest_date)
df["company"] = df["company"].astype(str).str.strip()
df["crop"] = df["crop"].astype(str).str.strip()

df = df.dropna(subset=["harvest_date", "company", "crop", "amount_kg"])
df = df[(df["company"] != "") & (df["crop"] != "")]
df = df[["harvest_date", "company", "crop", "amount_kg"]].copy()

st.markdown("### ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆç™»éŒ²å¯¾è±¡ï¼‰")
st.dataframe(df.head(30), use_container_width=True)

if df.empty:
    st.warning("æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚CSVå†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

result_box = st.container()

if st.button("ã“ã®å†…å®¹ã§DBã«ç™»éŒ²", type="primary"):
    ensure_table()
    eng = get_engine()

    rows = df.to_dict(orient="records")

    sql = """
    INSERT OR IGNORE INTO harvest_fact
    (harvest_date, company, crop, amount_kg)
    VALUES (:harvest_date, :company, :crop, :amount_kg)
    """

    try:
        with eng.begin() as conn:
            # ç™»éŒ²å‰ä»¶æ•°
            before_n = conn.execute(text("SELECT COUNT(*) FROM harvest_fact")).scalar_one()

            # ä¸€æ‹¬ç™»éŒ²ï¼ˆé‡è¤‡ã¯ç„¡è¦–ï¼‰
            conn.execute(text(sql), rows)

            # ç™»éŒ²å¾Œä»¶æ•°
            after_n = conn.execute(text("SELECT COUNT(*) FROM harvest_fact")).scalar_one()

        inserted = after_n - before_n
        skipped = len(rows) - inserted

        with result_box:
            st.success(f"ç™»éŒ²å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚è¿½åŠ : {inserted}ä»¶ / ã‚¹ã‚­ãƒƒãƒ—: {skipped}ä»¶ï¼ˆé‡è¤‡ãªã©ï¼‰")

            if skipped > 0:
                st.info("ã‚¹ã‚­ãƒƒãƒ—ç†ç”±ï¼šåŒä¸€ã‚­ãƒ¼ï¼ˆharvest_date, company, crop, amount_kgï¼‰ãŒæ—¢ã«DBã«å­˜åœ¨ã™ã‚‹ãŸã‚ã§ã™ã€‚")

            st.info(
                "ğŸ”„ ç™»éŒ²å†…å®¹ã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€å·¦ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ **Compass** ã¾ãŸã¯ **Search / List** ãƒšãƒ¼ã‚¸ã‚’é–‹ãç›´ã—ã¦ãã ã•ã„ã€‚\n"
                "ï¼ˆStreamlitã®ä»•æ§˜ä¸Šã€ä»–ãƒšãƒ¼ã‚¸ã®è¡¨ç¤ºã¯è‡ªå‹•æ›´æ–°ã•ã‚Œã¾ã›ã‚“ï¼‰"
            )

    except Exception as e:
        with result_box:
            st.error("DBç™»éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.exception(e)

