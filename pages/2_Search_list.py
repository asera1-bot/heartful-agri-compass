import pandas as pd
import streamlit as st
from sqlalchemy import text
from sqlalchemy.exc import SQLAlchemyError

from app.core.auth import require_login
from app.common.constants import DB_PATH

require_login()

st.set_page_config(page_title="Search List", layout="wide")
st.title("Search / List")
st.caption("åŽé‡ãƒ‡ãƒ¼ã‚¿ã‚’æ¡ä»¶ã§æ¤œç´¢ã—ã€ä¸€è¦§è¡¨ç¤ºãƒ»CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚")

try:
    df = load_harvest_df()
except Exception:
    st.info("ã¾ã ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚CSV Upload ã‹ã‚‰ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚")
    st.stop()
st.dataframe(df)

# --------------------
# DB Load
# --------------------
@st.cache_data
def load_hravest_df(db_mtime: float) -> pd.Dataframe:
    engine = get_engine()
    sql = "SELECT harvest_date, company, crop, amount_kg FROM harvest_fact ORDER BY harvest_date, company, crop"
    return pd.read_sql_query(sql, engine)

def get_harvest_df():
    mtime = DB_PATH.start().st_mtime if DB_PATH.exists() else 0.0
    return load_harvest_df(mtime)

    # harvest_date ã¯ TEXT(YYYY-MM-DD) æƒ³å®šã€‚å¿µã®ãŸã‚å¤‰æ›
    df["harvest_date"] = pd.to_datetime(df["harvest_date"], errors="coerce")
    df = df.dropna(subset=["harvest_date"])
    return df


with st.spinner("åŽé‡ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™..."):
    try:
        df = load_harvest_df()
    except SQLAlchemyError as e:
        st.error("DBèª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        st.code(str(DB_PATH), language="bash")
        st.exception(e)
        st.stop()

if df.empty:
    st.warning("åŽé‡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰/ETLã§ãƒ‡ãƒ¼ã‚¿ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# --------------------
# Filter UI
# --------------------
st.subheader("æ¤œç´¢æ¡ä»¶")

min_date = df["harvest_date"].min().date()
max_date = df["harvest_date"].max().date()

date_start, date_end = st.date_input(
    "å¯¾è±¡æœŸé–“",
    value=(min_date, max_date),
    min_value=min_date,
    max_value=max_date,
)

all_companies = sorted(df["company"].dropna().unique().tolist())
company_filter = st.multiselect("ä¼æ¥­ï¼ˆæœªé¸æŠžãªã‚‰å…¨ä»¶ï¼‰", options=all_companies, default=[])

all_crops = sorted(df["crop"].dropna().unique().tolist())
crop_filter = st.multiselect("ä½œç‰©ï¼ˆæœªé¸æŠžãªã‚‰å…¨ä»¶ï¼‰", options=all_crops, default=[])

# --------------------
# Apply filters
# --------------------
filtered = df[
    (df["harvest_date"].dt.date >= date_start)
    & (df["harvest_date"].dt.date <= date_end)
].copy()

if company_filter:
    filtered = filtered[filtered["company"].isin(company_filter)]

if crop_filter:
    filtered = filtered[filtered["crop"].isin(crop_filter)]

hit_count = len(filtered)

st.markdown("### ðŸ” æ¤œç´¢çµæžœ")
st.subheader(f"æ¤œç´¢çµæžœ: {hit_count} è¡Œ")

if hit_count == 0:
    st.warning("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# --------------------
# Pagination (only ONE table)
# --------------------
page_size = st.selectbox("è¡¨ç¤ºä»¶æ•°", [25, 50, 100, 200], index=0)

# âœ… page åˆæœŸåŒ–ï¼ˆKeyErroré˜²æ­¢ï¼‰
if "page" not in st.session_state:
    st.session_state["page"] = 1

# ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ãŒå¤‰ã‚ã£ãŸã‚‰ãƒšãƒ¼ã‚¸ã‚’1ã«æˆ»ã™ï¼ˆäº‹æ•…é˜²æ­¢ï¼‰
sig = (
    f"{date_start}|{date_end}|"
    + "|".join(company_filter)
    + "|"
    + "|".join(crop_filter)
    + f"|{page_size}|{hit_count}"
)
if st.session_state.get("_sig") != sig:
    st.session_state["_sig"] = sig
    st.session_state["page"] = 1

max_page = max(1, (hit_count + page_size - 1) // page_size)

col_prev, col_mid, col_next = st.columns([1, 2, 1])
with col_prev:
    if st.button("â† å‰", use_container_width=True) and st.session_state["page"] > 1:
        st.session_state["page"] -= 1
with col_mid:
    st.write(f"ãƒšãƒ¼ã‚¸ {st.session_state['page']} / {max_page}")
with col_next:
    if st.button("æ¬¡ â†’", use_container_width=True) and st.session_state["page"] < max_page:
        st.session_state["page"] += 1

start = (st.session_state["page"] - 1) * page_size
end = start + page_size

view = filtered.sort_values(["harvest_date", "company", "crop"]).iloc[start:end]

st.dataframe(view, use_container_width=True)
st.success(f"{hit_count} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ãŒãƒ’ãƒƒãƒˆã—ã¾ã—ãŸã€‚")

# --------------------
# CSV download
# --------------------
csv_bytes = (
    filtered.sort_values(["harvest_date", "company", "crop"])
    .to_csv(index=False)
    .encode("utf-8-sig")
)
st.download_button(
    label="æ¤œç´¢çµæžœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
    data=csv_bytes,
    file_name="harvest_search_result.csv",
    mime="text/csv",
)

